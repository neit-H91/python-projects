# IMDb ETL Pipeline Project

This project implements a complete ETL (Extract, Transform, Load) pipeline for processing and analyzing IMDb movie data. It transforms raw data into clean, analyzed datasets ready for use and querying.

## Pipeline Architecture

### 1. Extraction and Validation (Scripts/extract.py)
- **Data Loading**: Import raw CSV files from `Data/raw/`
- **Initial Cleaning**: Convert gross and runtime columns (remove text formats)
- **Data Validation**:
  - Schema verification (expected columns)
  - Data type validation
  - Value range checks (years, ratings, scores)
  - Uniqueness verification (Movie Title and Release Year)
  - Positive/Negative value checks
  - Null value detection

### 2. Transformation (Scripts/transform.py)
- **Derived Columns Addition**:
  - `Decade` Column: Groups movies by decade
  - `Rating` Column: Weighted average of IMDb and Metacritic ratings
- **New DataFrames Creation**:
  - Genre explosion for genre-based analysis
  - Actor column merging for actor-based analysis

### 3. Loading (pipeline.py)
- Save cleaned data in `Data/cleaned/`
- Generate multiple views:
  - `cleaned_imdb.csv`: Main transformed data
  - `cleaned_imdb_genres.csv`: Movies exploded by genre
  - `cleaned_imdb_actors.csv`: Actor data

### 4. Cloud Deployment (Scripts/cloud.py)
- Upload cleaned data to Google Cloud Storage
- Create BigQuery dataset if it doesn't exist
- Load data into BigQuery tables for scalable analytics

### 5. Logging (Scripts/log.py)
- Complete logging of all pipeline steps
- Logs saved in `Logs/pipeline_{dd_mm_yyyy}.log` (current date in dd_mm_yyyy format)
- Error levels to identify data issues

## Project Structure

```
/imdb/
├── Data/
│   ├── raw/
│   │   └── imdb_top_1000.csv
│   └── cleaned/  # Generated by pipeline
├── Logs/         # Pipeline logs
├── Scripts/
│   ├── extract.py    # Extraction and validation
│   ├── transform.py  # Transformations
│   ├── cloud.py      # Cloud operations
│   └── log.py        # Logging functions
├── pipeline.py       # Main execution script
├── requirements.txt  # Python dependencies
├── .python-version   # Pyenv version
└── readme.md         # This file
```

## Installation and Usage

1. **Environment**: The project uses pyenv for Python version management
2. **Dependency Installation**:
   ```
   pip install -r requirements.txt
   ```
3. **Pipeline Execution**:
   ```
   python pipeline.py
   ```

## Processed Data

- **Source**: `imdb_top_1000.csv` (1000 top IMDb movies)
- **Main Columns**: Title, Year, Genre, Ratings, Director, Actors, Revenue, etc.
- **Outputs**: Cleaned data and analysis-ready datasets

## Technologies Used

- **Python** with pyenv for version management
- **Pandas** and **NumPy** for data processing
- **Google Cloud Storage** for data storage
- **BigQuery** for data warehousing
- **Python Logging** for operation tracking
